{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from util import *\n",
    "from estimator import *\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "batch = 10000\n",
    "tau = tf.placeholder(tf.float32)\n",
    "lr  = tf.placeholder(tf.float32)\n",
    "x = tf.placeholder(tf.float32,[batch,784])\n",
    "cc  = tf.placeholder(tf.float32,[200])\n",
    "dd  = tf.placeholder(tf.float32)\n",
    "kk  = tf.placeholder(tf.float32,[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nets(estimator):\n",
    "    h = slim.stack(x,slim.fully_connected,[400])\n",
    "    h = slim.fully_connected(h,200,activation_fn=None)\n",
    "    z = tf.nn.sigmoid(h)\n",
    "    u = tf.random_uniform(tf.shape(z))\n",
    "    s = tf.reshape(estimator(z,u,tau,cc,dd,kk), [-1,200])\n",
    "    h2= slim.stack(slim.flatten(s),slim.fully_connected,[400])\n",
    "    y = slim.fully_connected(h2,784,activation_fn=None)\n",
    "    \n",
    "    kld = tf.reduce_sum(z*(tf.log(z+eps)-tf.log(.5)) + (1-z)*(tf.log(1-z+eps)-tf.log(.5)), 1)\n",
    "    nll = tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=y)\n",
    "    elbo= tf.reduce_sum(nll,1) + kld\n",
    "\n",
    "    return tf.reduce_mean(elbo), elbo, tf.nn.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def fit_model(filename, _lr, t, c, k):\n",
    "    steps = 100\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())        \n",
    "        saver = tf.train.Saver()\n",
    "        train_loss = np.empty((steps))\n",
    "        val_loss   = np.empty((steps))    \n",
    "        test_loss  = np.empty((steps))\n",
    "        var_g      = np.empty((steps))\n",
    "        \n",
    "        d = 2.\n",
    "        for i in xrange(steps*1000):\n",
    "            batch_ = np.reshape(random.sample(data_train, batch), [batch,-1])\n",
    "            batch_ = (np.random.uniform(0.,1.,[batch,784])<batch_).astype(float)\n",
    "            _, res = sess.run([train,loss],{x:batch_, tau:t, lr:_lr, cc:c, dd:d, kk:k})\n",
    "            if i%1000==1:\n",
    "                var_g[i/1000] = sess.run(vg,{x:batch_, tau:t, lr:_lr, cc:c, dd:d, kk:k})\n",
    "                \n",
    "                if filename[:2]=='MX':\n",
    "                    d = 3. - np.minimum(np.exp(-0.00001*i), 1.)\n",
    "                    c = np.exp(-0.00001*i)\n",
    "                    k = 1. - np.minimum(np.exp(-0.00001*i),0.1)\n",
    "                else:\n",
    "                    t = np.maximum(np.exp(-0.00003*i),0.1)\n",
    "\n",
    "\n",
    "                train_loss[i/1000] = res\n",
    "                batch_ = np.reshape(random.sample(data_val, batch), [batch,-1])\n",
    "                val_loss[i/1000] = sess.run(loss,{x:batch_, tau:0.001, lr:_lr, cc:1., dd:1., kk:5.})\n",
    "                batch_ = np.reshape(random.sample(data_test, batch), [batch,-1])\n",
    "                test_loss[i/1000] = sess.run(loss,{x:batch_, tau:0.001, lr:_lr, cc:1., dd:1., kk:5.})\n",
    "    \n",
    "                print train_loss[i/1000], test_loss[i/1000], var_g[i/1000]\n",
    "\n",
    "        np.save('VAE/OMNIGLOT/'+filename+'/loss_rec', [train_loss, val_loss, test_loss, var_g])\n",
    "        save_path = saver.save(sess, 'VAE/OMNIGLOT/'+filename+\"/model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting dataset/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting dataset/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting dataset/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting dataset/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data_train, data_val, data_test = bmnist()\n",
    "#data_train, data_val, data_test = bomniglot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loss, vl, _ = nets(mse)\n",
    "vg = [jacobian(vl, slim.get_model_variables()[z]) for z in range(4)]\n",
    "vg = [tf.reduce_mean(tf.square(z-tf.reduce_mean(z,0))) for z in vg]\n",
    "vg = tf.reduce_mean(vg)\n",
    "\n",
    "train=tf.train.AdamOptimizer(learning_rate=lr).minimize(loss,var_list=slim.get_model_variables())\n",
    "fit_model('MX1e-3', 1e-3, .1, 1., .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen(dn,mn):\n",
    "    with tf.Session() as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        batch_xs = data_test\n",
    "        s_ = []\n",
    "        s_.append(batch_xs[:100])\n",
    "        for ii in mn:\n",
    "            saver.restore(sess, dn+ii+\"/model.ckpt\")\n",
    "            tl, s = sess.run([tnll,ss], {x: batch_xs})\n",
    "            print tl\n",
    "            s_.append(s[:100])\n",
    "        return batch_xs[:100], s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from VAE/MNIST/GB1e-3/model.ckpt\n",
      "107.568\n",
      "INFO:tensorflow:Restoring parameters from VAE/MNIST/ST1e-3/model.ckpt\n",
      "118.094\n",
      "INFO:tensorflow:Restoring parameters from VAE/MNIST/AST1e-3/model.ckpt\n",
      "112.013\n",
      "INFO:tensorflow:Restoring parameters from VAE/MNIST/MX1e-3_7.0/model.ckpt\n",
      "106.047\n"
     ]
    }
   ],
   "source": [
    "tnll, _, ss = nets(discrete)\n",
    "a, b = gen('VAE/MNIST/',\n",
    "           ['GB1e-3','ST1e-3','AST1e-3','MX1e-3_7.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from VAE/OMNIGLOT/GB1e-3/model.ckpt\n",
      "121.863\n",
      "INFO:tensorflow:Restoring parameters from VAE/OMNIGLOT/ST3e-4/model.ckpt\n",
      "131.992\n",
      "INFO:tensorflow:Restoring parameters from VAE/OMNIGLOT/AST3e-4/model.ckpt\n",
      "122.555\n",
      "INFO:tensorflow:Restoring parameters from VAE/OMNIGLOT/MX1e-3_3.0/model.ckpt\n",
      "120.959\n"
     ]
    }
   ],
   "source": [
    "tnll, _, ss = nets(discrete)\n",
    "a, b = gen('VAE/OMNIGLOT/',\n",
    "           ['GB1e-3','ST3e-4','AST3e-4','MX1e-3_3.0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw(a,b,'64',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
