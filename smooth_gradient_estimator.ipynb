{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "Bernoulli = tf.contrib.distributions.Bernoulli\n",
    "\n",
    "data = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "for i in range(55000):\n",
    "    data.train.images[i] = (np.random.uniform(0.,1.,784)<data.train.images[i]).astype(float)\n",
    "for i in range(5000):\n",
    "    data.validation.images[i] = (np.random.uniform(0.,1.,784)<data.validation.images[i]).astype(float)\n",
    "for i in range(10000):\n",
    "    data.test.images[i] = (np.random.uniform(0.,1.,784)<data.test.images[i]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mul_b(p, w):\n",
    "    p = tf.concat([p, tf.ones([tf.shape(p)[0],1])], 1)\n",
    "    return tf.nn.sigmoid(tf.matmul(p, w))\n",
    "\n",
    "def bandwidth(p):\n",
    "    u = tf.tile(tf.reduce_mean(tf.reshape(p,[ns,-1,nn]),0),[ns,1])\n",
    "    s = tf.sqrt(tf.reduce_sum(tf.reshape(tf.square(p-u),[ns,-1,nn]),0)/(tf.cast(ns,tf.float32)-1.))\n",
    "    bw = 1.06 * s / tf.pow(tf.cast(ns,tf.float32), 0.2)\n",
    "    return tf.tile(bw, [ns,1])\n",
    "\n",
    "def dirac(p, bw):\n",
    "    return tf.check_numerics(1./(bw * np.sqrt(2*np.pi) + eps) * tf.exp(.5 * tf.square(p/(bw+eps))), 'dirac')\n",
    "\n",
    "def straight_through(p, z):\n",
    "    return tf.stop_gradient(tf.ceil(p-z) - p) + p\n",
    "\n",
    "def step_sample(p, z, dbw):\n",
    "    return tf.stop_gradient(tf.ceil(p-z) - dbw*p) + tf.stop_gradient(dbw)*p\n",
    "    \n",
    "def smooth_sample(p, z, bw):\n",
    "    s = (p-z) / (tf.sqrt(2*tf.square(bw)) + eps)\n",
    "    return tf.check_numerics(0.5 * (1 + tf.erf(s)), 'erf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "lr  = tf.placeholder(tf.float32)\n",
    "eps = 1e-7\n",
    "dim = 392\n",
    "nn  = 200\n",
    "ns  = tf.placeholder(tf.int32)\n",
    "\n",
    "\n",
    "wxh  = tf.Variable(tf.random_normal([dim+1,nn], stddev=np.sqrt(2.55e-3)))\n",
    "why  = tf.Variable(tf.random_normal([nn+1,dim], stddev=np.sqrt(5e-3)))\n",
    "\n",
    "\n",
    "y_  = tf.placeholder(tf.float32, [None, dim])\n",
    "x   = tf.placeholder(tf.float32, [None, dim])\n",
    "\n",
    "h  = mul_b(x,  wxh)\n",
    "nh = tf.tile(h, [ns,1])\n",
    "sd = tf.random_uniform(tf.shape(nh))\n",
    "\n",
    "#sh = straight_through(nh, sd)\n",
    "bw = bandwidth(nh-sd)\n",
    "#dw = dirac(nh-sd,bw)\n",
    "#sh = step_sample(nh, sd, dw)\n",
    "sh = smooth_sample(nh, sd, bw)\n",
    "\n",
    "y  = mul_b(sh,why)\n",
    "\n",
    "ye  = tf.reduce_mean(tf.reshape(y,[ns,-1,dim]),0)\n",
    "yy  = tf.pow(ye+eps, y_) * tf.pow(1-ye+eps, 1-y_)\n",
    "nll = tf.reduce_mean(tf.reduce_sum(-tf.log(yy),1))\n",
    "\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "train = opt.minimize(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model(steps, filename, _lr, _ns):\n",
    "    train_loss = np.empty((1000, steps/1000))\n",
    "    test_loss = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(steps):\n",
    "            batch_   = data.train.next_batch(24)[0]\n",
    "            batch_xs = batch_[:, 0:392]\n",
    "            batch_ys = batch_[:, 392:784]\n",
    "            res = sess.run([nll, train], {x: batch_xs, y_: batch_ys, ns: _ns, lr: _lr}) \n",
    "\n",
    "            train_loss[i%1000, i/1000] = res[0]\n",
    "            if (i+1)%1000==0:\n",
    "                batch_   = data.test.next_batch(100)[0]\n",
    "                batch_xs = batch_[:, 0:392]\n",
    "                batch_ys = batch_[:, 392:784]\n",
    "                res = sess.run(nll, {x: batch_xs, y_: batch_ys, ns: _ns, lr: _lr})                 \n",
    "                test_loss.append(res)\n",
    "\n",
    "        np.save(filename, [train_loss, test_loss])\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erf10 = fit_model(500000, \"erf10\", 1e-3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "erf20 = fit_model(500000, \"erf20\", 1e-3, 20)"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
